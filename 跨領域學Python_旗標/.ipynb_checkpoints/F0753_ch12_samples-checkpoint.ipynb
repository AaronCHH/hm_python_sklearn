{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F0753 範例程式 - 第 12 章 運用機器學習做分類 (classication) 預測及資料簡化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12-0 資料分類 (classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12-1 KNN (K 近鄰) 預測模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *匯入並分割資料集*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = datasets.load_wine(return_X_y=True)\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *建立 KNN 模型來預測分類*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 1 0 2 1 1 0 1 0 2 0 1 0 0 1 0 1 0 2 1 1 1 1 1 2 2 0 0 1 0 0 0]\n",
      "[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 1 0 1 0 0 1 1 1 1 1 1 2 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 沿用上一小節的套件及 data_train, data_test, target_train, target_test\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(data_train, target_train)\n",
    "predictions = knn.predict(data_test)\n",
    "\n",
    "print(predictions)\n",
    "print(target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *評估預測結果*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789\n",
      "0.806\n"
     ]
    }
   ],
   "source": [
    "# 沿用上一小節的套件及 knn, data_train, data_test, target_train, target_test\n",
    "\n",
    "print(knn.score(data_train, target_train).round(3))\n",
    "print(knn.score(data_test, target_test).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        14\n",
      "           1       0.88      0.88      0.88        16\n",
      "           2       0.40      0.33      0.36         6\n",
      "\n",
      "    accuracy                           0.81        36\n",
      "   macro avg       0.71      0.71      0.71        36\n",
      "weighted avg       0.79      0.81      0.80        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 沿用上一小節的 predictions\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(target_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *(bonus) 如何找出最適合的 K 值？*\n",
    "\n",
    "雖然書上說你得自行試驗並尋找最合適的 K 值, 但 scikit-learn 其實提供了個半自動解決辦法。下面的程式會使用 GridSearchCV 來搜尋預測效果最好的 n_neighbors 參數。(當然, 預測效果仍會因資料集的分割方式而有所變動。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "data, target = datasets.load_wine(return_X_y=True)\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, test_size=0.2, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors': np.arange(10) + 1}  # 指定 n_neighbors 測試範圍 (1~10)\n",
    "clf = GridSearchCV(knn, parameters)\n",
    "clf.fit(data_train, target_train)\n",
    "\n",
    "print(clf.best_params_)  # 印出測試範圍中最佳的 n_neighbors 參數值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 邏輯斯 (Logistic) 迴歸模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *訓練邏輯斯迴歸模型並預測資料*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = datasets.load_wine(return_X_y=True)\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 2 0 0 0 1 1 1 1 1 1 1 2 0 0 1 0 0 0]\n",
      "[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 1 0 1 0 0 1 1 1 1 1 1 2 0 0 1 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aaronhsu\\miniconda38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(data_train, target_train)\n",
    "predictions = log_model.predict(data_test)\n",
    "\n",
    "print(predictions)\n",
    "print(target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *評估預測成效*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986\n",
      "0.917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        14\n",
      "           1       0.93      0.88      0.90        16\n",
      "           2       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.91      0.93      0.92        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 沿用上一小節的 log_model, ata_train, data_test, target_train, target_test, predictions\n",
    "\n",
    "print(log_model.score(data_train, target_train).round(3))\n",
    "print(log_model.score(data_test, target_test).round(3))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(target_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12-3 改善邏輯斯迴歸模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *增加迭代次數、資料標準化 (standardization)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data, target = datasets.load_wine(return_X_y=True)\n",
    "\n",
    "sc = StandardScaler()\n",
    "data_std = sc.fit_transform(data)\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data_std, target, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression(max_iter=10000, verbose=True)\n",
    "log_model.fit(data_train, target_train)\n",
    "predictions = log_model.predict(data_test)\n",
    "\n",
    "print(log_model.score(data_train, target_train).round(3))\n",
    "print(log_model.score(data_test, target_test).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12-4 主成分分析 (PCA)：減少需分析的變數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *用線性支援向量 (SVM) 機建立預測模型*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.995\n",
      "0.956\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data, target = datasets.load_digits(return_X_y=True)\n",
    "\n",
    "sc = StandardScaler()\n",
    "data_std = sc.fit_transform(data)\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data_std, target, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC(max_iter=10000)\n",
    "svc.fit(data_train, target_train)\n",
    "predictions = svc.predict(data_test)\n",
    "\n",
    "print(svc.score(data_train, target_train).round(3))\n",
    "print(svc.score(data_test, target_test).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *檢視特徵值的變異程度*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.149 0.136 0.118 0.084 0.058 0.049 0.043 0.037 0.034 0.031 0.024 0.023\n",
      " 0.018 0.018 0.015 0.014 0.013 0.012 0.01  0.009 0.009 0.008 0.008 0.007\n",
      " 0.007 0.006 0.006 0.005 0.005 0.004 0.004 0.004 0.003 0.003 0.003 0.003\n",
      " 0.003 0.002 0.002 0.002 0.002 0.002 0.002 0.001 0.001 0.001 0.001 0.001\n",
      " 0.001 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.   ]\n"
     ]
    }
   ],
   "source": [
    "# 沿用上一小節的 data\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(data)\n",
    "print(pca.explained_variance_ratio_.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *用 PCA 篩選特徵值*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.149 0.136 0.118 0.084 0.058 0.049 0.043 0.037 0.034 0.031 0.024 0.023\n",
      " 0.018 0.018 0.015 0.014 0.013]\n"
     ]
    }
   ],
   "source": [
    "# 沿用上一小節的套件及 data\n",
    "\n",
    "pca = PCA(n_components=0.85)\n",
    "pca.fit(data)\n",
    "print(pca.explained_variance_ratio_.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.149 0.136 0.118 0.084 0.058 0.049 0.043 0.037 0.034 0.031]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=10)\n",
    "pca.fit(data)\n",
    "print(pca.explained_variance_ratio_.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *拿簡化過的資料來訓練模型*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.963\n",
      "0.956\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "data, target = datasets.load_digits(return_X_y=True)\n",
    "\n",
    "pca = PCA(n_components=0.85)\n",
    "data_pca = pca.fit_transform(data)\n",
    "\n",
    "sc = StandardScaler()\n",
    "data_std = sc.fit_transform(data_pca)\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data_std, target, test_size=0.2, random_state=42)\n",
    "\n",
    "svc = LinearSVC(max_iter=10000)\n",
    "svc.fit(data_train, target_train)\n",
    "predictions = svc.predict(data_test)\n",
    "\n",
    "print(svc.score(data_train, target_train).round(3))\n",
    "print(svc.score(data_test, target_test).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (bonus) 保存和重複使用預測模型\n",
    "\n",
    "在訓練好模型後, 你可用以下程式將模型儲存在磁碟中, 以利日後重複使用, 不必每次執行程式都得重新訓練模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = r'data\\svc_model'  # 檔案路徑和名稱\n",
    "\n",
    "pickle.dump(svc, open(filename, 'wb'))  # 將 svc 模型物件寫入到二進位檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(max_iter=10000)\n",
      "[6 9 3 7 2]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "filename = r'data\\svc_model'  # 檔案路徑和名稱\n",
    "\n",
    "saved_model = pickle.load(open(filename, 'rb'))  # 讀取二進位檔, 還原成模型物件 saved_model\n",
    "\n",
    "print(saved_model)  # 檢視模型\n",
    "print(saved_model.predict(data_test[0:5]))  # 預測資料 (使用 data_test 的前 5 筆資料)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
